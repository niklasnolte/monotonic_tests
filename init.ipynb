{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monotonenorm import GroupSort, get_normed_weights\n",
    "from torch.nn.utils.parametrizations import orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16\n",
    "hidden_dim = 16\n",
    "depth = 4\n",
    "lip = 5\n",
    "#activation = lambda: torch.nn.ReLU()\n",
    "activation = lambda: GroupSort(hidden_dim//2)\n",
    "#from monotonenorm import direct_norm\n",
    "direct_norm = lambda x, *args, **kwargs: x  # make it a normal network\n",
    "\n",
    "input = torch.randn(1000, input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "  torch.nn.Identity(),\n",
    "  direct_norm(torch.nn.Linear(input_dim,hidden_dim), kind=\"one\", alpha=lip ** ( 1 / depth)),\n",
    "  activation()\n",
    "]\n",
    "for i in range(depth - 2):\n",
    "  layers.append(\n",
    "    direct_norm(torch.nn.Linear(hidden_dim,hidden_dim), kind=\"one\", alpha=lip ** ( 1 / depth))\n",
    "  )\n",
    "  layers.append(activation())\n",
    "layers.append(\n",
    "  direct_norm(torch.nn.Linear(hidden_dim,1), kind=\"one\", alpha=lip ** ( 1 / depth))\n",
    ")\n",
    "model = torch.nn.Sequential(*layers).requires_grad_(False)\n",
    "\n",
    "\n",
    "for i in model.modules():\n",
    "  if isinstance(i, torch.nn.Linear):\n",
    "    torch.nn.init.orthogonal_(i.weight)\n",
    "    #i.weight.data *= input_dim ** (.5 / depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Identity()                                                   std 1.0037, mean 0.0125\n",
      "1, Linear(in_features=16, out_features=16, bias=True)           std 1.0036, mean -0.0849\n",
      "2, GroupSort(num_groups: {self.n_groups})                       std 0.8303, mean -0.0849\n",
      "3, Linear(in_features=16, out_features=16, bias=True)           std 0.8275, mean -0.0705\n",
      "4, GroupSort(num_groups: {self.n_groups})                       std 0.7199, mean -0.0705\n",
      "5, Linear(in_features=16, out_features=16, bias=True)           std 0.7196, mean -0.1614\n",
      "6, GroupSort(num_groups: {self.n_groups})                       std 0.6303, mean -0.1614\n",
      "7, Linear(in_features=16, out_features=1, bias=True)            std 0.5381, mean 0.0939\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model)):\n",
    "  print(f\"{i}, {str(model[i]):<60} std {model[:i+1](input).std(0).mean().item():.4f}, mean {model[:i+1](input).mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "want: f(x) ~ P(0,1)\n",
    "g(x) ~ P(0,1) ?\n",
    "\n",
    "want:\n",
    "f(x) = 1/idim(g(x) + 1x) ~ P(0,1), x_i ~ P(0,1) --> sum(x_i) ~ P(0,i_dim)\n",
    "g(x) ~ P(0,.5), 1x ~ P(0,.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_norm = lambda x: get_normed_weights(x, kind=\"one\", alpha=1, always_norm=False, vectorwise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(1)\n",
    "i = torch.randn(100, 2)\n",
    "t = torch.randn(2,2)\n",
    "torch.nn.init.orthogonal_(t)\n",
    "o = i @ do_norm(t).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8168), tensor(1.1281))"
      ]
     },
     "execution_count": 730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.var(0).mean(), i.var(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1942, -0.9810],\n",
       "         [-0.9810, -0.1942]]),\n",
       " tensor([[ 0.1653, -0.8347],\n",
       "         [-0.8347, -0.1653]]))"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, do_norm(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000]) tensor([1.0000, 1.0000])\n",
      "tensor([1.0000, 1.0000]) tensor([1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "p = 1#float('inf')\n",
    "print(do_norm(t).norm(dim=0, p=p), do_norm(t).norm(dim=1, p=p))\n",
    "print(t.norm(dim=0, p=2), t.norm(dim=1, p=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "#householder reflection\n",
    "def householder_reflection(v):\n",
    "  return torch.eye(v.shape[0]) - 2 * v @ v.T / (v.T @ v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = householder_reflection(torch.tensor([1., 0.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.tensor([1., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1., -2.])"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v @ hh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f66b475c7f3c7893d2633464dcd70b93c7a03e563e2680bf00b3479051dc13c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
