{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from monotonenorm import GroupSort, get_normed_weights\n",
    "from torch.nn.utils.parametrizations import orthogonal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean norm1: 0.2907, mean norminf: 25.4665, mean norm20: 0.1470, mean norm21: 1.0000\n"
     ]
    }
   ],
   "source": [
    "dims = (5, 1000)\n",
    "norminfs, norm1s, norm20s, norm21s = [], [], [], []\n",
    "for i in range(100):\n",
    "  torch.manual_seed(i)\n",
    "  t = torch.randn(*dims)\n",
    "  torch.nn.init.orthogonal_(t)\n",
    "  norm1s.append(t.norm(dim=0, p=1).max().item())\n",
    "  norminfs.append(t.norm(dim=1, p=1).max().item())\n",
    "  norm20s.append(t.norm(dim=0, p=2).max().item())\n",
    "  norm21s.append(t.norm(dim=1, p=2).max().item())\n",
    "  \n",
    "print(f\"mean norm1: {np.mean(norm1s):.4f}, mean norminf: {np.mean(norminfs):.4f}, mean norm20: {np.mean(norm20s):.4f}, mean norm21: {np.mean(norm21s):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(torch.nn.Module):\n",
    "    def __init__(self, f):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 256\n",
    "hidden_dim = 16\n",
    "depth = 4\n",
    "per_layer_lip = hidden_dim**.5\n",
    "#activation = lambda: torch.nn.ReLU()\n",
    "activation = lambda: GroupSort(hidden_dim // 2)\n",
    "from monotonenorm import direct_norm\n",
    "#direct_norm = lambda x, *args, **kwargs: x  # make it a normal network\n",
    "\n",
    "input = torch.randn(1000, input_dim)\n",
    "lip = per_layer_lip**depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "  torch.nn.Identity(),\n",
    "  direct_norm(torch.nn.Linear(input_dim,hidden_dim), kind=\"one-inf\", alpha=per_layer_lip),\n",
    "  activation()\n",
    "]\n",
    "for i in range(depth - 2):\n",
    "  layers.append(\n",
    "    direct_norm(torch.nn.Linear(hidden_dim,hidden_dim), kind=\"inf\", alpha=per_layer_lip)\n",
    "  )\n",
    "  layers.append(activation())\n",
    "layers.append(\n",
    "  direct_norm(torch.nn.Linear(hidden_dim,1), kind=\"inf\", alpha=per_layer_lip)\n",
    ")\n",
    "layers.append(\n",
    "  Lambda(lambda x: x/lip)\n",
    ")\n",
    "model = torch.nn.Sequential(*layers).requires_grad_(False)\n",
    "\n",
    "\n",
    "for i in model.modules():\n",
    "  if isinstance(i, torch.nn.Linear):\n",
    "    #continue\n",
    "    torch.nn.init.orthogonal_(i.weight)\n",
    "    #i.weight.data *= input_dim ** (.5 / depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Identity()                                                   std 0.9993, mean -0.0030\n",
      "1, Linear(in_features=256, out_features=16, bias=True)          std 1.0077, mean -0.0224\n",
      "2, GroupSort(num_groups: {self.n_groups})                       std 0.8351, mean -0.0224\n",
      "3, Linear(in_features=16, out_features=16, bias=True)           std 0.8329, mean -0.2274\n",
      "4, GroupSort(num_groups: {self.n_groups})                       std 0.7247, mean -0.2274\n",
      "5, Linear(in_features=16, out_features=16, bias=True)           std 0.7246, mean 0.2984\n",
      "6, GroupSort(num_groups: {self.n_groups})                       std 0.6585, mean 0.2984\n",
      "7, Linear(in_features=16, out_features=1, bias=True)            std 0.6490, mean 0.2821\n",
      "8, Lambda()                                                     std 0.0025, mean 0.0011\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model)):\n",
    "  print(f\"{i}, {str(model[i]):<60} std {model[:i+1](input).std(0).mean().item():.4f}, mean {model[:i+1](input).mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monotonic network with reasonable size starting configuration\n",
    "\n",
    "input_dim = 256\n",
    "hidden_dim = 16\n",
    "depth = 4\n",
    "per_layer_lip = hidden_dim**.5\n",
    "activation = lambda: GroupSort(hidden_dim // 2)\n",
    "from monotonenorm import direct_norm\n",
    "#direct_norm = lambda x, *args, **kwargs: x  # make it a normal network\n",
    "\n",
    "input = torch.randn(1000, input_dim)\n",
    "lip = per_layer_lip**depth\n",
    "\n",
    "\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    layers = [\n",
    "      direct_norm(torch.nn.Linear(input_dim,hidden_dim), kind=\"one-inf\"),\n",
    "      activation()\n",
    "    ]\n",
    "    for i in range(depth - 2):\n",
    "      layers.append(\n",
    "        direct_norm(torch.nn.Linear(hidden_dim,hidden_dim), kind=\"inf\")\n",
    "      )\n",
    "      layers.append(activation())\n",
    "    layers.append(\n",
    "      direct_norm(torch.nn.Linear(hidden_dim,1), kind=\"inf\")\n",
    "    )\n",
    "    self.layers = torch.nn.ModuleList(layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    for i in self.layers:\n",
    "      y = i(y)\n",
    "    return y + x.sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=256, out_features=16, bias=True)\n",
      "    (1): GroupSort(num_groups: {self.n_groups})\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): GroupSort(num_groups: {self.n_groups})\n",
      "    (4): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (5): GroupSort(num_groups: {self.n_groups})\n",
      "    (6): Linear(in_features=16, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f66b475c7f3c7893d2633464dcd70b93c7a03e563e2680bf00b3479051dc13c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
